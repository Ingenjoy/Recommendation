{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAY04-01 wide_and_deep.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ingenjoy/Recommendation-System/blob/master/DAY04_01_wide_and_deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEpgSYK0PXTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.optimizers import Adam\n",
        "import easydict\n",
        "\n",
        "\n",
        "# feature로 이용할 컬럼 정의\n",
        "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\",\n",
        "          \"occupation\", \"relationship\", \"race\", \"gender\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
        "# ?          \n",
        "LABEL_COLUMN = \"label\"\n",
        "# 범주형 Feature\n",
        "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
        "# 숫자형 Feature\n",
        "NUMERICAL_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpNhcDkxo2kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wide 모델\n",
        "class Wide:\n",
        "    def __init__(self, args):\n",
        "        self.learning_rate = args.learning_rate\n",
        "        self.epochs = args.epochs\n",
        "        self.batch_size = args.batch_size\n",
        "        self.input_dim = args.input_dim\n",
        "        self.model = self.classifier()\n",
        "\n",
        "    def classifier(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(1, activation='sigmoid', input_dim=self.input_dim))\n",
        "        optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def fit(self, x, y):\n",
        "      # validation_split : validation set 20%\n",
        "        self.model.fit(x, y, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.2)\n",
        "\n",
        "    def print_performance(self, x, y):\n",
        "        performance_test = self.model.evaluate(x, y, batch_size=self.batch_size)\n",
        "        print('Test Loss and Accuracy ->', performance_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDe7lhaAommZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deeo 모델\n",
        "class Deep:\n",
        "    def __init__(self, args):\n",
        "        self.learning_rate = args.learning_rate\n",
        "        self.epochs = args.epochs\n",
        "        self.batch_size = args.batch_size\n",
        "        self.input_dim = args.input_dim\n",
        "        self.model = self.classifier()\n",
        "\n",
        "    def classifier(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(100, activation='relu', input_dim=self.input_dim))\n",
        "        model.add(Dense(50, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.model.fit(x, y, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.2)\n",
        "\n",
        "    def print_performance(self, x, y):\n",
        "        performance_test = self.model.evaluate(x, y, batch_size=self.batch_size)\n",
        "        print('Test Loss and Accuracy ->', performance_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK9rxfjWotkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WideAndDeep:\n",
        "    def __init__(self, args):\n",
        "        self.learning_rate = args.learning_rate\n",
        "        self.epochs = args.epochs\n",
        "        self.batch_size = args.batch_size\n",
        "        self.input_dim = args.input_dim\n",
        "        self.model = self.classifier()\n",
        "\n",
        "    def classifier(self):\n",
        "        optimizer = Adam(lr=self.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "        # wide part\n",
        "        wide = Input(shape=(self.input_dim,))\n",
        "\n",
        "        # deep part\n",
        "        deep_input = Input(shape=(self.input_dim,))\n",
        "        deep = Dense(100, activation='relu')(deep_input)\n",
        "        deep = Dense(50, activation='relu')(deep)\n",
        "\n",
        "        # concatenate : wide and deep\n",
        "        wide_n_deep = concatenate([wide, deep])\n",
        "        wide_n_deep = Dense(1, activation='sigmoid')(wide_n_deep)\n",
        "        model = Model(inputs=[wide, deep_input], outputs=wide_n_deep)\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def fit(self, wide_x, deep_x, y):\n",
        "        self.model.fit([wide_x, deep_x], y, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.2)\n",
        "\n",
        "    def print_performance(self, wide_x, deep_x, y):\n",
        "        performance_test = self.model.evaluate([wide_x, deep_x], y, batch_size=self.batch_size)\n",
        "        print('Test Loss and Accuracy ->', performance_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3jpoVvaMjhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(model_param):\n",
        "    # prepare dataset\n",
        "    df_train = pd.read_csv('http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data',\n",
        "                           header=None,\n",
        "                           names=COLUMNS,\n",
        "                           skipinitialspace=True)\n",
        "    df_test = pd.read_csv('http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test',\n",
        "                          header=None,\n",
        "                          names=COLUMNS,\n",
        "                          skipinitialspace=True,\n",
        "                          skiprows=1)\n",
        "    df = pd.concat([df_train, df_test])\n",
        "    df[LABEL_COLUMN] = df['income_bracket'].apply(lambda x: \">50K\" in x).astype(int)\n",
        "    y = df[LABEL_COLUMN].values\n",
        "    df.pop(LABEL_COLUMN)\n",
        "    df.pop(\"income_bracket\")\n",
        "    df = pd.get_dummies(df, columns=[x for x in CATEGORICAL_COLUMNS])\n",
        "    df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns=df.columns)\n",
        "    x = df.values\n",
        "\n",
        "    # split train, test\n",
        "    train_length = len(df_train)\n",
        "    x_train = x[:train_length]\n",
        "    y_train = y[:train_length]\n",
        "    x_test = x[train_length:]\n",
        "    y_test = y[train_length:]\n",
        "\n",
        "    args = easydict.EasyDict({\n",
        "            \"batch_size\": 500,\n",
        "            \"epochs\": 30,\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"input_dim\": x_train.shape[1]\n",
        "    })\n",
        "\n",
        "    if model_param == \"deep\":\n",
        "        deep = Deep(args)\n",
        "        deep.fit(x_train, y_train)\n",
        "        deep.print_performance(x_test, y_test)\n",
        "    elif model_param == 'wide':\n",
        "        wide = Wide(args)\n",
        "        wide.fit(x_train, y_train)\n",
        "        wide.print_performance(x_test, y_test)\n",
        "    else:\n",
        "        wide_n_deep = WideAndDeep(args)\n",
        "        wide_n_deep.fit(x_train, x_train, y_train)\n",
        "        wide_n_deep.print_performance(x_test, x_test, y_test)\n",
        "\n",
        "        # prediction for individual\n",
        "        x_predict_test = x_test[np.newaxis, 0, :]\n",
        "        y_predict_test = y_test[0]\n",
        "        result = wide_n_deep.model.predict([x_predict_test, x_predict_test])\n",
        "        print('result predicted:', result[0][0])\n",
        "        print('result predicted:', round(result[0][0]))\n",
        "        print('result real:', y_predict_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMPWDuDqPs0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main('deep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj94LsxxRLwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main('wide')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2yCI4eNPchh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main('widendeep')\n",
        "\n",
        "    # score (test loss and acc)\n",
        "    # 1. wide : [0.34640224496809097, 0.8394447512213981]\n",
        "    # 2. deep : [0.3533135050656381, 0.8403660668860226]\n",
        "    # 3. wide and deep : [0.352460421507851, 0.8432528705885703]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8mPOmKSySBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}